{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency Over Time\n",
    "March 05, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook introduction\n",
    "This notebooks looks at multiple text files within a single folder and counts every time a certain word is used in each individual text within the file. For the convenience of not having to input search words individually they are combined into \"keyword lists.\" The function searches for each instance of each word in the list and outputs the number of results for each word in each text (along with the file name of the particular text file they come in so I can ID them).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string #am I actually using this now? If not, take out...\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = glob.glob(\"data/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list.sort() #sorting the list -- the file names in my folder are chronological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing to see if it is picking up all the issues in the folder by asking for total # of files\n",
    "len(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_search(wordlist):\n",
    "    \"\"\"\n",
    "    This function opens every text file within a folder, and counts each occurrence of each word from a specific /\n",
    "    list of keywords within the text.\n",
    "    \n",
    "    Input: predefined list of words\n",
    "    Output: the filename of the file being searched (for issue identification purposes) /\n",
    "    and a count of how many times each word on the word list appears in that file.\n",
    "    \"\"\"\n",
    "    \n",
    "    for filename in filename_list:\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "            file.close()\n",
    "        issue_lc = file_contents.lower() #making the text lower case\n",
    "        \n",
    "        tokens = word_tokenize(issue_lc) #taking advantage of the tokenizing function within NLTK\n",
    "    \n",
    "        tokens_nltk = nltk.Text(tokens) #taking advantage of the tokenizing function within NLTK\n",
    "    \n",
    "        wordcount_dict = {} #setting up an empty dictionary to hold results\n",
    "    \n",
    "        for word in wordlist:\n",
    "            wdcount = tokens_nltk.count(word)\n",
    "            newcount = {word: wdcount}\n",
    "            wordcount_dict.update(newcount)\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(filename, wordcount_dict) #output filename -for ID- and associated results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danger_words = ['unsafe', 'hazard', 'risk', \\\n",
    "                'peril', 'injury', 'injure', 'destroy', 'damage', 'accident', 'accidents', 'accidental',\\\n",
    "                'hurt', 'harm', 'collapse', 'danger', 'dangerous',\\\n",
    "                'death', 'fatal', 'fatality', 'catastrophe', 'disaster',\\\n",
    "                'unhealthy', 'victim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_words = ['safe', 'safety', 'protection', 'protect', 'welfare', 'safeguard', 'safeguards', 'avert', \\\n",
    "                 'prevent', 'wellbeing', 'guard', 'avoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsibility_words = ['liability', 'responsibility', 'compensation', 'negligent', 'negligence', \"neglected\", 'neglect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_words = ['health', 'healthy', 'lung', 'lungs', 'dust', 'illness', 'disease', 'sick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_words = ['environment', 'scenic', 'picturesque', 'pollution', 'effluence', 'smog', 'smoke', 'fumes', \\\n",
    "                     'contamination']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a sample of using the keyword_search function to look for safety-related words in the text\n",
    "\n",
    "safety_list = key_search(safety_words)\n",
    "print(safety_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This piece of code gives me a total word count for each issue to use in normalizing word counts\n",
    "\n",
    "for filename in filename_list:\n",
    "        with open(filename) as file:\n",
    "            file_contents = file.read()\n",
    "            file.close()\n",
    "        \n",
    "        length = (len(file_contents))\n",
    "        \n",
    "        print(filename, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
